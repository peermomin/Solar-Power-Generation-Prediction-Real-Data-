{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6ab895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b314e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1 = pd.read_csv(\".././Data Sets/Plant_1_Generation_Data.csv\")\n",
    "weather1 = pd.read_csv(\".././Data Sets/Plant_1_Weather_Sensor_Data.csv\")\n",
    "\n",
    "gen2 = pd.read_csv(\".././Data Sets/Plant_2_Generation_Data.csv\")\n",
    "weather2 = pd.read_csv(\".././Data Sets/Plant_2_Weather_Sensor_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d5b6ae",
   "metadata": {},
   "source": [
    "- Convert DATE_TIME Columns to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885efd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peerm\\AppData\\Local\\Temp\\ipykernel_11304\\4063308798.py:2: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'], errors='coerce', dayfirst=True)\n",
      "C:\\Users\\peerm\\AppData\\Local\\Temp\\ipykernel_11304\\4063308798.py:2: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'], errors='coerce', dayfirst=True)\n",
      "C:\\Users\\peerm\\AppData\\Local\\Temp\\ipykernel_11304\\4063308798.py:2: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'], errors='coerce', dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "for df in [gen1, weather1, gen2, weather2]:\n",
    "    df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'], errors='coerce', dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc872bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen1 0\n",
      "weather1 0\n",
      "gen2 0\n",
      "weather2 0\n"
     ]
    }
   ],
   "source": [
    "for name, df in zip(['gen1', 'weather1', 'gen2', 'weather2'], [gen1, weather1, gen2, weather2]):\n",
    "    print(name, df['DATE_TIME'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6566a393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "gen1: (68778, 7)\n",
      "weather1: (3182, 6)\n",
      "gen2: (67698, 7)\n",
      "weather2: (3259, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"gen1:\", gen1.shape)\n",
    "print(\"weather1:\", weather1.shape)\n",
    "print(\"gen2:\", gen2.shape)\n",
    "print(\"weather2:\", weather2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56eb941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant 1 generation columns: ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY', 'DC_POWER', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD']\n",
      "Plant 1 weather columns: ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']\n",
      "Plant 2 generation columns: ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY', 'DC_POWER', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD']\n",
      "Plant 2 weather columns: ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Clean column names and inspect key columns\n",
    "\n",
    "for df in [gen1, weather1, gen2, weather2]:\n",
    "    df.columns = df.columns.str.strip()  # remove extra spaces\n",
    "\n",
    "print(\"Plant 1 generation columns:\", gen1.columns.tolist())\n",
    "print(\"Plant 1 weather columns:\", weather1.columns.tolist())\n",
    "print(\"Plant 2 generation columns:\", gen2.columns.tolist())\n",
    "print(\"Plant 2 weather columns:\", weather2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d085a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "gen1: (68778, 7)\n",
      "weather1: (3182, 6)\n",
      "gen2: (67698, 7)\n",
      "weather2: (3259, 6)\n"
     ]
    }
   ],
   "source": [
    "# Step : Drop missing or invalid rows before merging\n",
    "\n",
    "# Drop rows where DATE_TIME is missing\n",
    "gen1.dropna(subset=['DATE_TIME'], inplace=True)\n",
    "weather1.dropna(subset=['DATE_TIME'], inplace=True)\n",
    "gen2.dropna(subset=['DATE_TIME'], inplace=True)\n",
    "weather2.dropna(subset=['DATE_TIME'], inplace=True)\n",
    "\n",
    "# Drop any remaining NaNs just in case\n",
    "for df in [gen1, weather1, gen2, weather2]:\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"gen1:\", gen1.shape)\n",
    "print(\"weather1:\", weather1.shape)\n",
    "print(\"gen2:\", gen2.shape)\n",
    "print(\"weather2:\", weather2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fec7448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged successfully using nearest timestamps!\n",
      "Plant 1 shape: (68778, 11)\n",
      "Plant 2 shape: (67698, 11)\n"
     ]
    }
   ],
   "source": [
    "# Step : Merge generation and weather data (using nearest timestamp)\n",
    "def merge_nearest(gen, weather):\n",
    "    # Sort both by datetime\n",
    "    gen = gen.sort_values('DATE_TIME')\n",
    "    weather = weather.sort_values('DATE_TIME')\n",
    "    \n",
    "    # Merge based on the nearest timestamp (within 10 minutes)\n",
    "    merged = pd.merge_asof(\n",
    "        gen, weather,\n",
    "        on='DATE_TIME',\n",
    "        by='PLANT_ID',\n",
    "        tolerance=pd.Timedelta('10min'),\n",
    "        direction='nearest'\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "plant1 = merge_nearest(gen1, weather1)\n",
    "plant2 = merge_nearest(gen2, weather2)\n",
    "\n",
    "print(\"âœ… Merged successfully using nearest timestamps!\")\n",
    "print(\"Plant 1 shape:\", plant1.shape)\n",
    "print(\"Plant 2 shape:\", plant2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e30219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added time features!\n",
      "Sample columns: ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY_x', 'DC_POWER', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD', 'SOURCE_KEY_y', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION', 'HOUR', 'DAY', 'MONTH']\n"
     ]
    }
   ],
   "source": [
    "# Step : Add time features (hour, day, month)\n",
    "\n",
    "for df in [plant1, plant2]:\n",
    "    df['HOUR'] = df['DATE_TIME'].dt.hour\n",
    "    df['DAY'] = df['DATE_TIME'].dt.day\n",
    "    df['MONTH'] = df['DATE_TIME'].dt.month\n",
    "\n",
    "print(\"Added time features!\")\n",
    "print(\"Sample columns:\", plant1.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c3118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f320a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 8253 zero-power rows. Remaining: 68845\n",
      "âœ… Data ready for model training!\n",
      "X shape: (68845, 5)\n",
      "y shape: (68845,)\n",
      "\n",
      "Sample X rows:\n",
      "     AMBIENT_TEMPERATURE  MODULE_TEMPERATURE  IRRADIATION  HOUR  MONTH\n",
      "510            24.088446           22.206757     0.005887     6      5\n",
      "511            24.088446           22.206757     0.005887     6      5\n",
      "512            24.088446           22.206757     0.005887     6      5\n",
      "513            24.088446           22.206757     0.005887     6      5\n",
      "514            24.088446           22.206757     0.005887     6      5\n",
      "\n",
      "Sample y rows:\n",
      "510    41.857143\n",
      "511    57.000000\n",
      "512    54.625000\n",
      "513    54.625000\n",
      "514    38.625000\n",
      "Name: DC_POWER, dtype: float64\n",
      "\n",
      "âœ… Cleaned dataset saved successfully as 'Cleaned_Solar_Data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step : Clean and prepare final data for model training\n",
    "\n",
    "# Drop unwanted or duplicate columns\n",
    "for df in [plant1, plant2]:\n",
    "    for col in ['PLANT_ID_x', 'PLANT_ID_y']:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Combine both plants into one dataset\n",
    "combined = pd.concat([plant1, plant2], ignore_index=True)\n",
    "\n",
    "# Drop rows where key features are missing\n",
    "combined.dropna(subset=['DC_POWER', 'AMBIENT_TEMPERATURE',\n",
    "                        'MODULE_TEMPERATURE', 'IRRADIATION'], inplace=True)\n",
    "\n",
    "# Filter out rows with IRRADIATION = 0 (nighttime â€” no solar output)\n",
    "combined = combined[combined['IRRADIATION'] > 0]\n",
    "\n",
    "# Step : Filter out rows with zero DC power\n",
    "before = combined.shape[0]\n",
    "combined = combined[combined['DC_POWER'] > 0]\n",
    "after = combined.shape[0]\n",
    "print(f\"Filtered out {before - after} zero-power rows. Remaining: {after}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "combined.drop(columns=['PLANT_ID', 'SOURCE_KEY_x', 'SOURCE_KEY_y', 'DAY'], inplace=True)\n",
    "\n",
    "# Convert date to datetime\n",
    "combined['DATE_TIME'] = pd.to_datetime(combined['DATE_TIME'])\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "features = ['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION', 'HOUR', 'MONTH']\n",
    "X = combined[features]\n",
    "y = combined['DC_POWER']\n",
    "\n",
    "print(\"âœ… Data ready for model training!\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"\\nSample X rows:\")\n",
    "print(X.head())\n",
    "print(\"\\nSample y rows:\")\n",
    "print(y.head())\n",
    "\n",
    "# ðŸ’¾ Step 8: Save cleaned dataset for reuse\n",
    "combined.to_csv(\".././Data Sets/Cleaned_Solar_Data.csv\", index=False)\n",
    "print(\"\\nâœ… Cleaned dataset saved successfully as 'Cleaned_Solar_Data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d34286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (68845, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined shape:\", combined.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
